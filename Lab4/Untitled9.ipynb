{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ebf4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A1\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "original_audio, sr = librosa.load('recording.wav', sr=None)\n",
    "trimmed_audio, index = librosa.effects.trim(original_audio)\n",
    "sf.write('trimmed_audio.wav', trimmed_audio, sr)\n",
    "trimmed,sr1 = librosa.load('trimmed_audio.wav',sr = None)\n",
    "\n",
    "print(\"Original Audio:\")\n",
    "ipd.display(ipd.Audio(original_audio, rate=sr))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveshow(original_audio, sr=sr,color='black')\n",
    "plt.title('Original')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Trimmed Audio:\")\n",
    "ipd.display(ipd.Audio(trimmed_audio, rate=sr))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "librosa.display.waveshow(trimmed, sr=sr1,color='green')\n",
    "plt.title('Trimmed')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a6ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "\n",
    "recorded_speech, sr = librosa.load('recording.wav', sr=None)\n",
    "\n",
    "def split_and_save(top_db):\n",
    "    segments = librosa.effects.split(recorded_speech, top_db=top_db)\n",
    "    c = ['blue','red','green','orange']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(recorded_speech, color=random.choice(c), label='Recorded Speech')\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        start, end = segment\n",
    "        segment_audio = recorded_speech[start:end]\n",
    "        sf.write(f'segment_{i}.wav', segment_audio, sr)\n",
    "\n",
    "    plt.title(f\"Recorded Speech with Segments (top_db={top_db})\")\n",
    "    plt.xlabel('Sample')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "top_db_values = [1, 10, 20,40]\n",
    "\n",
    "for top_db in top_db_values:\n",
    "    print(f\"Splitting with top_db={top_db}\")\n",
    "    split_and_save(top_db)\n",
    "\n",
    "# Listen to the generated signals\n",
    "for i in range(len(top_db_values)):\n",
    "    print(f\"Listening to segments with top_db={top_db_values[i]}:\")\n",
    "    for j in range(len(librosa.effects.split(recorded_speech, top_db=top_db_values[i]))):\n",
    "        ipd.display(ipd.Audio(f'segment_{j}.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sr = librosa.load(\"recording.wav\", sr=None)\n",
    "from librosa import display\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure()\n",
    "librosa.display.waveshow(y=signal, sr=sr) \n",
    "plt.xlabel(\"Time (seconds)\") \n",
    "plt.ylabel(\"Amplitude\") \n",
    "plt.show()\n",
    "\n",
    "n_fft = 2048\n",
    "S= librosa.stft(signal, n_fft=n_fft, hop_length=n_fft//2)\n",
    "print(S.shape)\n",
    "D = librosa.amplitude_to_db(np.abs(S), ref=np.max) \n",
    "np.max(abs(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mute = librosa.effects.split(signal)\n",
    "no_mute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayTime(startFrame, endFrame):    \n",
    "    print(' start time: ' + str(startFrame/sr) + ', end time: ' + str(endFrame/sr))\n",
    "for i in no_mute:\n",
    "    displayTime(i[0],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (start, end) in enumerate(no_mute):\n",
    "    displayTime(start, end)\n",
    "    if i % 2 == 0:\n",
    "        plt.axvspan(start/sr, end/sr, color='blue', alpha=0.3)  # Plot silence segments in blue\n",
    "    else:\n",
    "        plt.axvspan(start/sr, end/sr, color='orange', alpha=0.3)  # Plot non-silence segments in orange\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c993be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_amplitude = np.max(np.abs(signal))\n",
    "\n",
    "# Convert amplitude to dB\n",
    "signal_db = 20 * np.log10(np.abs(signal) / max_amplitude)\n",
    "\n",
    "# Plot the dB representation of the signal\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(signal_db, color='blue')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude (dB)')\n",
    "plt.title('Audio Signal in dB')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
